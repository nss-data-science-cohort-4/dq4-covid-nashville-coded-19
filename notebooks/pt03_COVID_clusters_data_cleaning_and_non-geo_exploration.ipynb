{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Clusters Data\n",
    "\n",
    "The Metro Public Health Department tracks COVID-19 clusters. The files `clusters.csv` and `clusters_by_type.csv` contain the tables of clusters as reported by [WSMV](https://www.wsmv.com/news/metro-health-releases-latest-covid-19-clusters/article_ef554e08-1558-11eb-b290-873345e174d7.html) along with the coordinates of the clusters. Can you find any connection between the reported COVID violations and subsequent COVID clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display settings\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and explore the COVID-19 clusters dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read this in as a normal dataframe first\n",
    "clusters = pd.read_csv('../data/clusters.csv')\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.columns = ['cluster_name', 'type', 'start_date', 'case_count', 'lat', 'long']\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large clusters without lat/long coordinates\n",
    "clusters[clusters['lat'].isna() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Of the 62 10+ people clusters named and recorded in the dataset, the 11 listed above do not have any associated coordinates and cannot be mapped._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up data types in the clusters dataframe\n",
    "clusters.start_date = pd.to_datetime(clusters['start_date'], errors = 'raise')\n",
    "# # Not necessary anymore\n",
    "# clusters.long = clusters.long.str.replace(',','')\n",
    "# clusters.long = pd.to_numeric(clusters['long'], errors = 'raise')\n",
    "# clusters.long.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the datatypes look good\n",
    "clusters.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What is the smallest cluster?\n",
    "clusters.case_count.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.to_csv('../data/clusters_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.groupby('type')['case_count'].sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many large clusters are identified by type\n",
    "big_clusters = clusters.type.value_counts().to_frame()\n",
    "big_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the index a column\n",
    "big_clusters.reset_index(inplace = True)\n",
    "big_clusters.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the type and cluster_count columns\n",
    "big_clusters = big_clusters.rename(columns = {'type' : 'cluster_count', 'index':'type'})\n",
    "big_clusters.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure it looks right\n",
    "big_clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the Clusters by Type dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are no coordinates, just read this in as a normal pandas dataframe\n",
    "clusters_by_type = pd.read_csv('../data/clusters_by_type.csv')\n",
    "clusters_by_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_by_type.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the column names\n",
    "clusters_by_type.columns = ['type', 'cluster_count']\n",
    "clusters_by_type.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the cluster types in the two dataframes\n",
    "print(clusters.sort_values('type').type.unique())\n",
    "print(clusters_by_type.sort_values('type').type.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list looks largely the same, though there are some cluster types that are not represented in the individual `clusters` dataset. Based on my understanding of COVID-19 data aggregation practices and the WSMV statement that only clusters of 10+ individuals are identified, I assume that the clusters represented in the `clusters` dataset are all of those that are `>= 10 cases` to protect the privacy of individuals diagnosed with COVID-19 in small clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the distribution of clusters by type\n",
    "clusters_by_type.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which type of facility is the outlier in terms of number of clusters? LTCF\n",
    "clusters_by_type[clusters_by_type['cluster_count'] > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the big cluster counts with the clusters_by_type dataframe\n",
    "clusters_by_type = clusters_by_type.merge(big_clusters, how = 'left', on = 'type', suffixes = ['_total', '_big'])\n",
    "clusters_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values so that the columns can be mathed\n",
    "clusters_by_type['cluster_count_big'] = clusters_by_type['cluster_count_big'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the small cluster count column by subtracting the large clusters from the total\n",
    "clusters_by_type['cluster_count_small'] = clusters_by_type.cluster_count_total - clusters_by_type.cluster_count_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all the types to integers\n",
    "clusters_by_type = clusters_by_type.astype({'cluster_count_big' : 'int64', 'cluster_count_small' : 'int64'})\n",
    "clusters_by_type = clusters_by_type.sort_values('cluster_count_total', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_by_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure it looks good\n",
    "clusters_by_type.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart here of side-by-side cluster sizes\n",
    "clusters_by_type.plot(kind = 'bar', x = 'type', y = ['cluster_count_big', 'cluster_count_small'], figsize = (20,10))\n",
    "plt.title('Large and Small COVID-19 Clusters by Facility Type', fontsize = 40)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Number of Clusters', fontsize = 14)\n",
    "plt.xticks(rotation = 290, fontsize = 14)\n",
    "plt.legend(['10+ COVID Cluster', 'Small COVID Cluster'], fontsize = 20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/large_and_small_clusters_by_type.png', dpi = 150)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figsize\n",
    "plt.figure(figsize=(20,10))\n",
    "# Set the range for bubble sizes\n",
    "minsize = min(clusters['case_count']*10)\n",
    "maxsize = max(clusters['case_count']*10)\n",
    "# make scatterplot\n",
    "fig = sns.scatterplot(data = clusters, x = 'start_date', y = 'case_count', hue = 'type', size = 'case_count', sizes=(minsize, maxsize), alpha = 0.7)\n",
    "fig.set_xlim(clusters['start_date'].min(), clusters['start_date'].max())\n",
    "# set labels\n",
    "plt.xlabel('Cluster Start Date', size=14)\n",
    "plt.ylabel('Number of Cases', size=14)\n",
    "plt.title('Large COVID-19 Case Clusters by Date', size=20)\n",
    "# Fix the legend\n",
    "h,l = fig.get_legend_handles_labels()\n",
    "plt.legend(h[1:15], l[1:15], loc= 'upper right', fontsize=14).set_title('')\n",
    "# plt.show(fig)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/large_clusters_over_time.png', dpi = 150);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the sizes of big clusters changing over time?\n",
    "clusters.plot(kind = 'scatter', x = 'start_date', y = 'case_count')\n",
    "plt.xticks(rotation = 45)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart of clusters over time\n",
    "clusters.plot(kind = 'line', x = 'start_date', y = 'case_count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_by_type.to_csv('../data/clusters_by_type_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the COVID-19 reported violations dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since I need to update a couple of items, reading this in as a pandas dataframe\n",
    "violations = pd.read_csv('../data/covid_violations.csv')\n",
    "violations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "violations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new datetime field for the date a violation was reported\n",
    "violations['date_opened'] = violations['datetime_opened'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert that field into datetime format\n",
    "violations['date_opened'] = pd.to_datetime(violations['date_opened'], errors = 'raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the datatypes\n",
    "violations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check out the coordinates that have 15 violations but only 3 locations\n",
    "violations[violations['coord'] == '(36.15658331160417, -86.78745279999998)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_These all appear to be generic 'Broadway' references. Since we're going to be matching locations from the Google API by address, I'm still leaving the addresses in in the following new dataframe subsets._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations.to_csv('../data/violations_cleaned.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe with a count of violations by coordinates\n",
    "violations_by_loc = violations.groupby(['long', 'lat', 'address']).count()\n",
    "# Sort the dataframe and take a look at the top-50 results\n",
    "violations_by_loc = violations_by_loc.sort_values(['request_no'], ascending = False)\n",
    "violations_by_loc.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the dataframe\n",
    "violations_by_loc = violations_by_loc.drop(['datetime_opened', 'contact_type', 'city', 'zip', 'coord', 'date_opened'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "violations_by_loc.reset_index(inplace = True)\n",
    "violations_by_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_by_loc.to_csv('../data/violations_by_loc.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "violations_by_date = violations.groupby(['date_opened']).count()\n",
    "# Sort the dataframe and take a look at the top-50 results\n",
    "violations_by_date = violations_by_date.sort_values(['request_no'], ascending = False)\n",
    "violations_by_date.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the dataframe\n",
    "violations_by_date.reset_index(inplace = True)\n",
    "violations_by_date = violations_by_date.drop(['datetime_opened', 'contact_type', 'address', 'city', 'zip', 'lat', 'long'], axis = 1)\n",
    "violations_by_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_by_date.columns = ['date_opened', 'total_violations', 'total_num_w_coords']\n",
    "violations_by_date.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_by_date.to_csv('../data/violations_by_date.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with a count of violations by coordinates\n",
    "violations_by_loc_and_date = violations.groupby(['long', 'lat', 'address', 'date_opened']).count()\n",
    "# Sort the dataframe and take a look at the top-50 results\n",
    "violations_by_loc_and_date = violations_by_loc_and_date.sort_values(['request_no'], ascending = False)\n",
    "violations_by_loc_and_date.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the dataframe\n",
    "violations_by_loc_and_date = violations_by_loc_and_date.drop(['datetime_opened', 'contact_type', 'city', 'zip', 'coord'], axis = 1)\n",
    "violations_by_loc_and_date.reset_index(inplace = True)\n",
    "violations_by_loc_and_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_by_loc_and_date.to_csv('../data/violations_by_loc_and_date.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
