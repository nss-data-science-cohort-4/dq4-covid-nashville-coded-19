{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Test to open a file\n",
    "# # with open('../data/google_places_results/results_01.json') as fi:\n",
    "# #     result = json.load(fi)\n",
    "\n",
    "# # # Alternate approach to reading in the json file\n",
    "# google_results = pd.read_json(r'../data/google_places_results/results_01.json')\n",
    "# google_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe with the columns we want\n",
    "column_names = ['mapped_location', 'address']\n",
    "result_addresses = pd.DataFrame(columns = column_names)\n",
    "\n",
    "# Go through and open each json results file\n",
    "for file in list(glob.glob('../data/google_places_results/*.json')):\n",
    "    with open(file) as fi:\n",
    "        result = json.load(fi)\n",
    "# Write the contents of the 'results' field to a dataframe       \n",
    "        google_results = pd.json_normalize(result)\n",
    "# Clean up the dataframe columns\n",
    "        google_results = google_results.drop(['results'], axis = 1)\n",
    "        google_results.columns = ['mapped_location', 'address']\n",
    "# Append the contents of each json file to the results dataframe\n",
    "        result_addresses = result_addresses.append(google_results)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_addresses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_addresses = result_addresses.reset_index()\n",
    "result_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_addresses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe with the columns we want\n",
    "column_names = ['name', 'types', 'address', 'lat', 'long']\n",
    "results = pd.DataFrame(columns = column_names)\n",
    "\n",
    "# Go through and open each json results file\n",
    "for file in list(glob.glob('../data/google_places_results/*.json')):\n",
    "    with open(file) as fi:\n",
    "        result = json.load(fi)\n",
    "# Write the contents of the 'results' field to a dataframe       \n",
    "        google_results = pd.json_normalize(result, 'results')\n",
    "# Clean up the dataframe columns\n",
    "        google_results = google_results.drop(['business_status', 'icon', 'place_id', 'rating', 'reference', 'scope', 'user_ratings_total', 'geometry.viewport.northeast.lat', 'geometry.viewport.northeast.lng', 'geometry.viewport.southwest.lat', 'geometry.viewport.southwest.lng', 'opening_hours.open_now', 'plus_code.compound_code', 'plus_code.global_code', 'photos', 'price_level', 'permanently_closed'], axis = 1)\n",
    "        google_results.columns = ['name', 'types', 'address', 'lat', 'long']\n",
    "# Append the contents of each json file to the results dataframe\n",
    "        results = results.append(google_results)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the dataframe we've created\n",
    "results.head()\n",
    "# Bask in its glory\n",
    "# Look on our works, ye mighty, and despair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_addresses = result_addresses.merge(results, how = 'left', on = 'address')\n",
    "result_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_addresses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_addresses[result_addresses['name'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_addresses['address'] = result_addresses['address'].str.replace(r',.+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe with the columns we want as well as an empty list for index numbers\n",
    "column_names = ['index', 'mapped_location', 'address', 'name', 'types', 'lat', 'long']\n",
    "result_addresses_unique = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for row in result_addresses:\n",
    "    index_list = []\n",
    "    if result_addresses['index'].isin(index_list) == True:\n",
    "        pass\n",
    "    else:\n",
    "        result_addresses_unique = result_addresses.append(row)\n",
    "        index_list.append(result_addresses['index'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_addresses.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = [1,2,3,4]\n",
    "result_addresses['index'].isin(index_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_addresses = result_addresses['address'].to_list()\n",
    "all_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the COVID-19 violation reports dataset\n",
    "violations = pd.read_csv('../data/covid_violations.csv')\n",
    "violations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_addresses = violations['address'].to_list()\n",
    "violations_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "violations_with_businesses = violations.merge(result_addresses, how = 'left', on = 'address')\n",
    "violations_with_businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_with_businesses[violations_with_businesses['name'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_with_businesses.address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
